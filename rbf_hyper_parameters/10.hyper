env_name,LunarLanderContinuous-v2,string
max_episode,200,integer
max_step,200000,integer
num_layers,3,integer
layer_size,512,integer
num_layers_action_side,1,integer
layer_size_action_side,512,integer
learning_rate,0.000025,float
learning_rate_location_side,0.000001,float
target_network_learning_rate,0.005,float
max_buffer_size,500000,integer
gamma,0.99,float
batch_size,256,integer
num_points,100,integer
reward_clip,20,float
temperature,2,float
policy_parameter,2.75,float
norm_smoothing,0.00001,float
updates_per_episode,1000,integer
dropout_rate,0.4,float
optimizer,Adam,string
policy_type,e_greedy,string
vmin,-600,integer
vmax,300,integer
num_atoms,51,integer
alpha,0.10,float
per_beta_start,0.4,float
update_frequency,1,integer
quantiles,200,integer
train_epsilon,0,float